dataset: biosses
subset: biosses_bigbio_pairs
templates:
  6c959d53-e6b0-4723-a63b-0b47b672bd81: !Template
    answer_choices: no ||| yes
    id: 6c959d53-e6b0-4723-a63b-0b47b672bd81
    jinja: 'Do "{{text_1}}" and "{{text_2}}" seem similar to you?|||

      {{answer_choices[0 if label|float < 2.5 else 1]}}

      '
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: bigbio_sts_seem_binary
    reference: ''
  9c87c669-7be0-42f3-bd38-32ff149f2722: !Template
    answer_choices: 0 ||| 1 ||| 2 ||| 3 ||| 4
    id: 9c87c669-7be0-42f3-bd38-32ff149f2722
    jinja: 'from {{"0.0"}} to {{"4.0"}}, how similar are "{{text_1}}" and "{{text_2}}"?|||

      {{label}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: bigbio_sts_similarity_scale
    reference: ''
  abc04725-8f0d-4653-a813-b9b41a45f253: !Template
    answer_choices: 0 ||| 1 ||| 2 ||| 3 ||| 4
    id: abc04725-8f0d-4653-a813-b9b41a45f253
    jinja: 'How similar are "{{text_1}}" and "{{text_2}}"? Give a score between {{"0.0"}}
      and {{"4.0"}}.|||

      {{label}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: bigbio_sts_similarity_how
    reference: ''
  d008ec2b-5e2e-4375-a937-6830782eb370: !Template
    answer_choices: no ||| yes
    id: d008ec2b-5e2e-4375-a937-6830782eb370
    jinja: 'Do you think "{{text_1}}" and "{{text_2}}" express the same thing?|||

      {{answer_choices[0 if label|float < 2.5 else 1]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: bigbio_sts_express_binary
    reference: ''
  e0b0f20b-47a8-459d-898e-d9a428706e20: !Template
    answer_choices: 0 ||| 1 ||| 2 ||| 3 ||| 4
    id: e0b0f20b-47a8-459d-898e-d9a428706e20
    jinja: 'Rate the similarity of these two sentences ({{"0.0"}} being the lowest
      and {{"4.0"}} the highest):

      "{{text_1}}" and "{{text_2}}"|||

      {{label}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: bigbio_sts_similarity_rate
    reference: ''
  8d47f5c4-f58c-42d4-a5e1-3ddf68edd875: !Template
    answer_choices: different topics ||| not equivalent ||| roughly equivalent |||
      mostly equivalent ||| completely equivalent
    id: 8d47f5c4-f58c-42d4-a5e1-3ddf68edd875
    jinja: "Read the following two sentences:\n\"{{text_1}}\"\n\n\"{{text_2}}\"\
      \n\nWhich statement best describes the sentences' semantic relatedness? \n0\
      \ different topics\n1 not equivalent\n2 roughly equivalent\n3 mostly equivalent\n\
      4 completely equivalent |||\n\n{{answer_choices[(label|int)]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: full label names
    reference: developed based on the original BIOSSES paper annotation guidelines

